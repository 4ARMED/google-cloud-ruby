---
layout: yard_main
title: "Class: Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics - Cloud"
css: 
  - /docs/css/style.css
  - /docs/css/common.css
  - /css/yard-main.css
js: 
  - /docs/js/app.js
  - /js/yard-main.js
---
<script type="text/javascript" charset="utf-8">
  pathId = "Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics";
  relpath = '../../../../';
</script>


<div class="nav_wrap">
  <iframe id="nav" src="../../../../class_list.html?1"></iframe>
  <div id="resizer"></div>
</div>

<div id="main" tabindex="-1">
  <div id="header">
    <div id="menu">
  
    <a href="../../../../_index.html">Index (C)</a> &raquo;
    <span class='title'><span class='object_link'><a href="../../../../Google.html" title="Google (module)">Google</a></span></span> &raquo; <span class='title'><span class='object_link'><a href="../../../Cloud.html" title="Google::Cloud (module)">Cloud</a></span></span> &raquo; <span class='title'><span class='object_link'><a href="../../AutoML.html" title="Google::Cloud::AutoML (module)">AutoML</a></span></span> &raquo; <span class='title'><span class='object_link'><a href="../V1beta1.html" title="Google::Cloud::AutoML::V1beta1 (module)">V1beta1</a></span></span>
     &raquo; 
    <span class="title">ClassificationEvaluationMetrics</span>
  
</div>

    <div id="search">
  
    <a class="full_list_link" id="class_list_link"
        href="../../../../class_list.html">

        <svg width="24" height="24">
          <rect x="0" y="4" width="24" height="4" rx="1" ry="1"></rect>
          <rect x="0" y="12" width="24" height="4" rx="1" ry="1"></rect>
          <rect x="0" y="20" width="24" height="4" rx="1" ry="1"></rect>
        </svg>
    </a>
  
</div>
    <div class="clear"></div>
  </div>

  <div id="content"><h1>Class: Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics
  
  
  
</h1>
<div class="box_info">
  
  <dl>
    <dt>Inherits:</dt>
    <dd>
      <span class="inheritName">Object</span>
      
        <ul class="fullTree">
          <li>Object</li>
          
            <li class="next">Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics</li>
          
        </ul>
        <a href="#" class="inheritanceTree">show all</a>
      
    </dd>
  </dl>
  

  
  
  
  
  

  

  
  <dl>
    <dt>Defined in:</dt>
    <dd>lib/google/cloud/automl/v1beta1/doc/google/cloud/automl/v1beta1/classification.rb</dd>
  </dl>
  
</div>

<h2>Overview</h2><div class="docstring">
  <div class="discussion">
    <p>Model evaluation metrics for classification problems.
Note: For Video Classification this metrics only describe quality of the
Video Classification predictions of &quot;segment_classification&quot; type.</p>


  </div>
</div>
<div class="tags">
  

</div><h2>Defined Under Namespace</h2>
<p class="children">
  
    
  
    
      <strong class="classes">Classes:</strong> <span class='object_link'><a href="ClassificationEvaluationMetrics/ConfidenceMetricsEntry.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry (class)">ConfidenceMetricsEntry</a></span>, <span class='object_link'><a href="ClassificationEvaluationMetrics/ConfusionMatrix.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix (class)">ConfusionMatrix</a></span>
    
  
</p>




  <h2>Instance Attribute Summary <small><a href="#" class="summary_toggle">collapse</a></small></h2>
  <ul class="summary">
    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#annotation_spec_id-instance_method" title="#annotation_spec_id (instance method)">#<strong>annotation_spec_id</strong>  &#x21d2; Array&lt;String&gt; </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>Output only.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#au_prc-instance_method" title="#au_prc (instance method)">#<strong>au_prc</strong>  &#x21d2; Float </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>Output only.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#au_roc-instance_method" title="#au_roc (instance method)">#<strong>au_roc</strong>  &#x21d2; Float </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>Output only.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#base_au_prc-instance_method" title="#base_au_prc (instance method)">#<strong>base_au_prc</strong>  &#x21d2; Float </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>Output only.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#confidence_metrics_entry-instance_method" title="#confidence_metrics_entry (instance method)">#<strong>confidence_metrics_entry</strong>  &#x21d2; Array&lt;Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry&gt; </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>Output only.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#confusion_matrix-instance_method" title="#confusion_matrix (instance method)">#<strong>confusion_matrix</strong>  &#x21d2; Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>Output only.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#log_loss-instance_method" title="#log_loss (instance method)">#<strong>log_loss</strong>  &#x21d2; Float </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>Output only.</p>
</div></span>
  
</li>

    
  </ul>





  <div id="instance_attr_details" class="attr_details">
    <h2>Instance Attribute Details</h2>
    
      
      <span id="annotation_spec_id=-instance_method"></span>
      <div class="method_details first">
  <h3 class="signature first" id="annotation_spec_id-instance_method">
  
    #<strong>annotation_spec_id</strong>  &#x21d2; <tt>Array&lt;String&gt;</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns Output only. The annotation spec ids used for this evaluation.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Array&lt;String&gt;</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>Output only. The annotation spec ids used for this evaluation.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/automl/v1beta1/doc/google/cloud/automl/v1beta1/classification.rb', line 102</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics (class)">ClassificationEvaluationMetrics</a></span></span>
  <span class='comment'># Metrics for a single confidence threshold.
</span>  <span class='comment'># @!attribute [rw] confidence_threshold
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     never returns predictions with score lower than this value.
</span>  <span class='comment'># @!attribute [rw] position_threshold
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     always returns at most this many predictions (ordered by their score,
</span>  <span class='comment'>#     descendingly), but they all still need to meet the confidence_threshold.
</span>  <span class='comment'># @!attribute [rw] recall
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Recall (True Positive Rate) for the given confidence
</span>  <span class='comment'>#     threshold.
</span>  <span class='comment'># @!attribute [rw] precision
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Precision for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. False Positive Rate for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] f1_score
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of recall and precision.
</span>  <span class='comment'># @!attribute [rw] recall_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The Recall (True Positive Rate) when only considering the
</span>  <span class='comment'>#     label that has the highest prediction score and not below the confidence
</span>  <span class='comment'>#     threshold for each example.
</span>  <span class='comment'># @!attribute [rw] precision_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The precision when only considering the label that has the
</span>  <span class='comment'>#     highest prediction score and not below the confidence threshold for each
</span>  <span class='comment'>#     example.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The False Positive Rate when only considering the label that
</span>  <span class='comment'>#     has the highest prediction score and not below the confidence threshold
</span>  <span class='comment'>#     for each example.
</span>  <span class='comment'># @!attribute [rw] f1_score_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#recall_at1 recall_at1} and {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#precision_at1 precision_at1}.
</span>  <span class='comment'># @!attribute [rw] true_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that match a ground truth
</span>  <span class='comment'>#     label.
</span>  <span class='comment'># @!attribute [rw] false_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that do not match a
</span>  <span class='comment'>#     ground truth label.
</span>  <span class='comment'># @!attribute [rw] false_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of ground truth labels that are not matched
</span>  <span class='comment'>#     by a model created label.
</span>  <span class='comment'># @!attribute [rw] true_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of labels that were not created by the model,
</span>  <span class='comment'>#     but if they would, they would not match a ground truth label.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfidenceMetricsEntry.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry (class)">ConfidenceMetricsEntry</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>

  <span class='comment'># Confusion matrix of the model running the classification.
</span>  <span class='comment'># @!attribute [rw] annotation_spec_id
</span>  <span class='comment'>#   @return [Array&lt;String&gt;]
</span>  <span class='comment'>#     Output only. IDs of the annotation specs used in the confusion matrix.
</span>  <span class='comment'>#     For Tables CLASSIFICATION
</span>  <span class='comment'>#
</span>  <span class='comment'>#     {Google::Cloud::AutoML::V1beta1::TablesModelMetadata#prediction_type prediction_type}
</span>  <span class='comment'>#     only list of {Annotation_spec_display_name-s} is populated.
</span>  <span class='comment'># @!attribute [rw] row
</span>  <span class='comment'>#   @return [Array&lt;Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix::Row&gt;]
</span>  <span class='comment'>#     Output only. Rows in the confusion matrix. The number of rows is equal to
</span>  <span class='comment'>#     the size of `annotation_spec_id`.
</span>  <span class='comment'>#     `row[i].value[j]` is the number of examples that have ground truth of the
</span>  <span class='comment'>#     `annotation_spec_id[i]` and are predicted as `annotation_spec_id[j]` by
</span>  <span class='comment'>#     the model being evaluated.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfusionMatrix.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix (class)">ConfusionMatrix</a></span></span>
    <span class='comment'># Output only. A row in the confusion matrix.
</span>    <span class='comment'># @!attribute [rw] example_count
</span>    <span class='comment'>#   @return [Array&lt;Integer&gt;]
</span>    <span class='comment'>#     Output only. Value of the specific cell in the confusion matrix.
</span>    <span class='comment'>#     The number of values each row has (i.e. the length of the row) is equal
</span>    <span class='comment'>#     to the length of the `annotation_spec_id` field or, if that one is not
</span>    <span class='comment'>#     populated, length of the {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix#display_name display_name} field.
</span>    <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="Row.html" title="Google::Cloud::AutoML::V1beta1::Row (class)">Row</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="au_prc=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="au_prc-instance_method">
  
    #<strong>au_prc</strong>  &#x21d2; <tt>Float</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns Output only. The Area Under Precision-Recall Curve metric. Micro-averaged
for the overall evaluation.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Float</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>Output only. The Area Under Precision-Recall Curve metric. Micro-averaged
for the overall evaluation.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/automl/v1beta1/doc/google/cloud/automl/v1beta1/classification.rb', line 102</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics (class)">ClassificationEvaluationMetrics</a></span></span>
  <span class='comment'># Metrics for a single confidence threshold.
</span>  <span class='comment'># @!attribute [rw] confidence_threshold
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     never returns predictions with score lower than this value.
</span>  <span class='comment'># @!attribute [rw] position_threshold
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     always returns at most this many predictions (ordered by their score,
</span>  <span class='comment'>#     descendingly), but they all still need to meet the confidence_threshold.
</span>  <span class='comment'># @!attribute [rw] recall
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Recall (True Positive Rate) for the given confidence
</span>  <span class='comment'>#     threshold.
</span>  <span class='comment'># @!attribute [rw] precision
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Precision for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. False Positive Rate for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] f1_score
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of recall and precision.
</span>  <span class='comment'># @!attribute [rw] recall_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The Recall (True Positive Rate) when only considering the
</span>  <span class='comment'>#     label that has the highest prediction score and not below the confidence
</span>  <span class='comment'>#     threshold for each example.
</span>  <span class='comment'># @!attribute [rw] precision_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The precision when only considering the label that has the
</span>  <span class='comment'>#     highest prediction score and not below the confidence threshold for each
</span>  <span class='comment'>#     example.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The False Positive Rate when only considering the label that
</span>  <span class='comment'>#     has the highest prediction score and not below the confidence threshold
</span>  <span class='comment'>#     for each example.
</span>  <span class='comment'># @!attribute [rw] f1_score_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#recall_at1 recall_at1} and {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#precision_at1 precision_at1}.
</span>  <span class='comment'># @!attribute [rw] true_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that match a ground truth
</span>  <span class='comment'>#     label.
</span>  <span class='comment'># @!attribute [rw] false_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that do not match a
</span>  <span class='comment'>#     ground truth label.
</span>  <span class='comment'># @!attribute [rw] false_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of ground truth labels that are not matched
</span>  <span class='comment'>#     by a model created label.
</span>  <span class='comment'># @!attribute [rw] true_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of labels that were not created by the model,
</span>  <span class='comment'>#     but if they would, they would not match a ground truth label.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfidenceMetricsEntry.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry (class)">ConfidenceMetricsEntry</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>

  <span class='comment'># Confusion matrix of the model running the classification.
</span>  <span class='comment'># @!attribute [rw] annotation_spec_id
</span>  <span class='comment'>#   @return [Array&lt;String&gt;]
</span>  <span class='comment'>#     Output only. IDs of the annotation specs used in the confusion matrix.
</span>  <span class='comment'>#     For Tables CLASSIFICATION
</span>  <span class='comment'>#
</span>  <span class='comment'>#     {Google::Cloud::AutoML::V1beta1::TablesModelMetadata#prediction_type prediction_type}
</span>  <span class='comment'>#     only list of {Annotation_spec_display_name-s} is populated.
</span>  <span class='comment'># @!attribute [rw] row
</span>  <span class='comment'>#   @return [Array&lt;Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix::Row&gt;]
</span>  <span class='comment'>#     Output only. Rows in the confusion matrix. The number of rows is equal to
</span>  <span class='comment'>#     the size of `annotation_spec_id`.
</span>  <span class='comment'>#     `row[i].value[j]` is the number of examples that have ground truth of the
</span>  <span class='comment'>#     `annotation_spec_id[i]` and are predicted as `annotation_spec_id[j]` by
</span>  <span class='comment'>#     the model being evaluated.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfusionMatrix.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix (class)">ConfusionMatrix</a></span></span>
    <span class='comment'># Output only. A row in the confusion matrix.
</span>    <span class='comment'># @!attribute [rw] example_count
</span>    <span class='comment'>#   @return [Array&lt;Integer&gt;]
</span>    <span class='comment'>#     Output only. Value of the specific cell in the confusion matrix.
</span>    <span class='comment'>#     The number of values each row has (i.e. the length of the row) is equal
</span>    <span class='comment'>#     to the length of the `annotation_spec_id` field or, if that one is not
</span>    <span class='comment'>#     populated, length of the {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix#display_name display_name} field.
</span>    <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="Row.html" title="Google::Cloud::AutoML::V1beta1::Row (class)">Row</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="au_roc=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="au_roc-instance_method">
  
    #<strong>au_roc</strong>  &#x21d2; <tt>Float</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns Output only. The Area Under Receiver Operating Characteristic curve metric.
Micro-averaged for the overall evaluation.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Float</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>Output only. The Area Under Receiver Operating Characteristic curve metric.
Micro-averaged for the overall evaluation.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/automl/v1beta1/doc/google/cloud/automl/v1beta1/classification.rb', line 102</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics (class)">ClassificationEvaluationMetrics</a></span></span>
  <span class='comment'># Metrics for a single confidence threshold.
</span>  <span class='comment'># @!attribute [rw] confidence_threshold
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     never returns predictions with score lower than this value.
</span>  <span class='comment'># @!attribute [rw] position_threshold
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     always returns at most this many predictions (ordered by their score,
</span>  <span class='comment'>#     descendingly), but they all still need to meet the confidence_threshold.
</span>  <span class='comment'># @!attribute [rw] recall
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Recall (True Positive Rate) for the given confidence
</span>  <span class='comment'>#     threshold.
</span>  <span class='comment'># @!attribute [rw] precision
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Precision for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. False Positive Rate for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] f1_score
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of recall and precision.
</span>  <span class='comment'># @!attribute [rw] recall_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The Recall (True Positive Rate) when only considering the
</span>  <span class='comment'>#     label that has the highest prediction score and not below the confidence
</span>  <span class='comment'>#     threshold for each example.
</span>  <span class='comment'># @!attribute [rw] precision_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The precision when only considering the label that has the
</span>  <span class='comment'>#     highest prediction score and not below the confidence threshold for each
</span>  <span class='comment'>#     example.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The False Positive Rate when only considering the label that
</span>  <span class='comment'>#     has the highest prediction score and not below the confidence threshold
</span>  <span class='comment'>#     for each example.
</span>  <span class='comment'># @!attribute [rw] f1_score_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#recall_at1 recall_at1} and {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#precision_at1 precision_at1}.
</span>  <span class='comment'># @!attribute [rw] true_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that match a ground truth
</span>  <span class='comment'>#     label.
</span>  <span class='comment'># @!attribute [rw] false_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that do not match a
</span>  <span class='comment'>#     ground truth label.
</span>  <span class='comment'># @!attribute [rw] false_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of ground truth labels that are not matched
</span>  <span class='comment'>#     by a model created label.
</span>  <span class='comment'># @!attribute [rw] true_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of labels that were not created by the model,
</span>  <span class='comment'>#     but if they would, they would not match a ground truth label.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfidenceMetricsEntry.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry (class)">ConfidenceMetricsEntry</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>

  <span class='comment'># Confusion matrix of the model running the classification.
</span>  <span class='comment'># @!attribute [rw] annotation_spec_id
</span>  <span class='comment'>#   @return [Array&lt;String&gt;]
</span>  <span class='comment'>#     Output only. IDs of the annotation specs used in the confusion matrix.
</span>  <span class='comment'>#     For Tables CLASSIFICATION
</span>  <span class='comment'>#
</span>  <span class='comment'>#     {Google::Cloud::AutoML::V1beta1::TablesModelMetadata#prediction_type prediction_type}
</span>  <span class='comment'>#     only list of {Annotation_spec_display_name-s} is populated.
</span>  <span class='comment'># @!attribute [rw] row
</span>  <span class='comment'>#   @return [Array&lt;Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix::Row&gt;]
</span>  <span class='comment'>#     Output only. Rows in the confusion matrix. The number of rows is equal to
</span>  <span class='comment'>#     the size of `annotation_spec_id`.
</span>  <span class='comment'>#     `row[i].value[j]` is the number of examples that have ground truth of the
</span>  <span class='comment'>#     `annotation_spec_id[i]` and are predicted as `annotation_spec_id[j]` by
</span>  <span class='comment'>#     the model being evaluated.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfusionMatrix.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix (class)">ConfusionMatrix</a></span></span>
    <span class='comment'># Output only. A row in the confusion matrix.
</span>    <span class='comment'># @!attribute [rw] example_count
</span>    <span class='comment'>#   @return [Array&lt;Integer&gt;]
</span>    <span class='comment'>#     Output only. Value of the specific cell in the confusion matrix.
</span>    <span class='comment'>#     The number of values each row has (i.e. the length of the row) is equal
</span>    <span class='comment'>#     to the length of the `annotation_spec_id` field or, if that one is not
</span>    <span class='comment'>#     populated, length of the {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix#display_name display_name} field.
</span>    <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="Row.html" title="Google::Cloud::AutoML::V1beta1::Row (class)">Row</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="base_au_prc=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="base_au_prc-instance_method">
  
    #<strong>base_au_prc</strong>  &#x21d2; <tt>Float</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns Output only. The Area Under Precision-Recall Curve metric based on priors.
Micro-averaged for the overall evaluation.
Deprecated.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Float</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>Output only. The Area Under Precision-Recall Curve metric based on priors.
Micro-averaged for the overall evaluation.
Deprecated.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/automl/v1beta1/doc/google/cloud/automl/v1beta1/classification.rb', line 102</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics (class)">ClassificationEvaluationMetrics</a></span></span>
  <span class='comment'># Metrics for a single confidence threshold.
</span>  <span class='comment'># @!attribute [rw] confidence_threshold
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     never returns predictions with score lower than this value.
</span>  <span class='comment'># @!attribute [rw] position_threshold
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     always returns at most this many predictions (ordered by their score,
</span>  <span class='comment'>#     descendingly), but they all still need to meet the confidence_threshold.
</span>  <span class='comment'># @!attribute [rw] recall
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Recall (True Positive Rate) for the given confidence
</span>  <span class='comment'>#     threshold.
</span>  <span class='comment'># @!attribute [rw] precision
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Precision for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. False Positive Rate for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] f1_score
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of recall and precision.
</span>  <span class='comment'># @!attribute [rw] recall_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The Recall (True Positive Rate) when only considering the
</span>  <span class='comment'>#     label that has the highest prediction score and not below the confidence
</span>  <span class='comment'>#     threshold for each example.
</span>  <span class='comment'># @!attribute [rw] precision_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The precision when only considering the label that has the
</span>  <span class='comment'>#     highest prediction score and not below the confidence threshold for each
</span>  <span class='comment'>#     example.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The False Positive Rate when only considering the label that
</span>  <span class='comment'>#     has the highest prediction score and not below the confidence threshold
</span>  <span class='comment'>#     for each example.
</span>  <span class='comment'># @!attribute [rw] f1_score_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#recall_at1 recall_at1} and {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#precision_at1 precision_at1}.
</span>  <span class='comment'># @!attribute [rw] true_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that match a ground truth
</span>  <span class='comment'>#     label.
</span>  <span class='comment'># @!attribute [rw] false_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that do not match a
</span>  <span class='comment'>#     ground truth label.
</span>  <span class='comment'># @!attribute [rw] false_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of ground truth labels that are not matched
</span>  <span class='comment'>#     by a model created label.
</span>  <span class='comment'># @!attribute [rw] true_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of labels that were not created by the model,
</span>  <span class='comment'>#     but if they would, they would not match a ground truth label.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfidenceMetricsEntry.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry (class)">ConfidenceMetricsEntry</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>

  <span class='comment'># Confusion matrix of the model running the classification.
</span>  <span class='comment'># @!attribute [rw] annotation_spec_id
</span>  <span class='comment'>#   @return [Array&lt;String&gt;]
</span>  <span class='comment'>#     Output only. IDs of the annotation specs used in the confusion matrix.
</span>  <span class='comment'>#     For Tables CLASSIFICATION
</span>  <span class='comment'>#
</span>  <span class='comment'>#     {Google::Cloud::AutoML::V1beta1::TablesModelMetadata#prediction_type prediction_type}
</span>  <span class='comment'>#     only list of {Annotation_spec_display_name-s} is populated.
</span>  <span class='comment'># @!attribute [rw] row
</span>  <span class='comment'>#   @return [Array&lt;Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix::Row&gt;]
</span>  <span class='comment'>#     Output only. Rows in the confusion matrix. The number of rows is equal to
</span>  <span class='comment'>#     the size of `annotation_spec_id`.
</span>  <span class='comment'>#     `row[i].value[j]` is the number of examples that have ground truth of the
</span>  <span class='comment'>#     `annotation_spec_id[i]` and are predicted as `annotation_spec_id[j]` by
</span>  <span class='comment'>#     the model being evaluated.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfusionMatrix.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix (class)">ConfusionMatrix</a></span></span>
    <span class='comment'># Output only. A row in the confusion matrix.
</span>    <span class='comment'># @!attribute [rw] example_count
</span>    <span class='comment'>#   @return [Array&lt;Integer&gt;]
</span>    <span class='comment'>#     Output only. Value of the specific cell in the confusion matrix.
</span>    <span class='comment'>#     The number of values each row has (i.e. the length of the row) is equal
</span>    <span class='comment'>#     to the length of the `annotation_spec_id` field or, if that one is not
</span>    <span class='comment'>#     populated, length of the {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix#display_name display_name} field.
</span>    <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="Row.html" title="Google::Cloud::AutoML::V1beta1::Row (class)">Row</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="confidence_metrics_entry=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="confidence_metrics_entry-instance_method">
  
    #<strong>confidence_metrics_entry</strong>  &#x21d2; <tt>Array&lt;<span class='object_link'><a href="ClassificationEvaluationMetrics/ConfidenceMetricsEntry.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry (class)">Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry</a></span>&gt;</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns Output only. Metrics for each confidence_threshold in
0.00,0.05,0.10,...,0.95,0.96,0.97,0.98,0.99 and
position_threshold = INT32_MAX_VALUE.
ROC and precision-recall curves, and other aggregated metrics are derived
from them. The confidence metrics entries may also be supplied for
additional values of position_threshold, but from these no aggregated
metrics are computed.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Array&lt;<span class='object_link'><a href="ClassificationEvaluationMetrics/ConfidenceMetricsEntry.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry (class)">Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry</a></span>&gt;</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>Output only. Metrics for each confidence_threshold in
0.00,0.05,0.10,...,0.95,0.96,0.97,0.98,0.99 and
position_threshold = INT32_MAX_VALUE.
ROC and precision-recall curves, and other aggregated metrics are derived
from them. The confidence metrics entries may also be supplied for
additional values of position_threshold, but from these no aggregated
metrics are computed.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/automl/v1beta1/doc/google/cloud/automl/v1beta1/classification.rb', line 102</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics (class)">ClassificationEvaluationMetrics</a></span></span>
  <span class='comment'># Metrics for a single confidence threshold.
</span>  <span class='comment'># @!attribute [rw] confidence_threshold
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     never returns predictions with score lower than this value.
</span>  <span class='comment'># @!attribute [rw] position_threshold
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     always returns at most this many predictions (ordered by their score,
</span>  <span class='comment'>#     descendingly), but they all still need to meet the confidence_threshold.
</span>  <span class='comment'># @!attribute [rw] recall
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Recall (True Positive Rate) for the given confidence
</span>  <span class='comment'>#     threshold.
</span>  <span class='comment'># @!attribute [rw] precision
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Precision for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. False Positive Rate for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] f1_score
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of recall and precision.
</span>  <span class='comment'># @!attribute [rw] recall_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The Recall (True Positive Rate) when only considering the
</span>  <span class='comment'>#     label that has the highest prediction score and not below the confidence
</span>  <span class='comment'>#     threshold for each example.
</span>  <span class='comment'># @!attribute [rw] precision_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The precision when only considering the label that has the
</span>  <span class='comment'>#     highest prediction score and not below the confidence threshold for each
</span>  <span class='comment'>#     example.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The False Positive Rate when only considering the label that
</span>  <span class='comment'>#     has the highest prediction score and not below the confidence threshold
</span>  <span class='comment'>#     for each example.
</span>  <span class='comment'># @!attribute [rw] f1_score_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#recall_at1 recall_at1} and {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#precision_at1 precision_at1}.
</span>  <span class='comment'># @!attribute [rw] true_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that match a ground truth
</span>  <span class='comment'>#     label.
</span>  <span class='comment'># @!attribute [rw] false_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that do not match a
</span>  <span class='comment'>#     ground truth label.
</span>  <span class='comment'># @!attribute [rw] false_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of ground truth labels that are not matched
</span>  <span class='comment'>#     by a model created label.
</span>  <span class='comment'># @!attribute [rw] true_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of labels that were not created by the model,
</span>  <span class='comment'>#     but if they would, they would not match a ground truth label.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfidenceMetricsEntry.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry (class)">ConfidenceMetricsEntry</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>

  <span class='comment'># Confusion matrix of the model running the classification.
</span>  <span class='comment'># @!attribute [rw] annotation_spec_id
</span>  <span class='comment'>#   @return [Array&lt;String&gt;]
</span>  <span class='comment'>#     Output only. IDs of the annotation specs used in the confusion matrix.
</span>  <span class='comment'>#     For Tables CLASSIFICATION
</span>  <span class='comment'>#
</span>  <span class='comment'>#     {Google::Cloud::AutoML::V1beta1::TablesModelMetadata#prediction_type prediction_type}
</span>  <span class='comment'>#     only list of {Annotation_spec_display_name-s} is populated.
</span>  <span class='comment'># @!attribute [rw] row
</span>  <span class='comment'>#   @return [Array&lt;Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix::Row&gt;]
</span>  <span class='comment'>#     Output only. Rows in the confusion matrix. The number of rows is equal to
</span>  <span class='comment'>#     the size of `annotation_spec_id`.
</span>  <span class='comment'>#     `row[i].value[j]` is the number of examples that have ground truth of the
</span>  <span class='comment'>#     `annotation_spec_id[i]` and are predicted as `annotation_spec_id[j]` by
</span>  <span class='comment'>#     the model being evaluated.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfusionMatrix.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix (class)">ConfusionMatrix</a></span></span>
    <span class='comment'># Output only. A row in the confusion matrix.
</span>    <span class='comment'># @!attribute [rw] example_count
</span>    <span class='comment'>#   @return [Array&lt;Integer&gt;]
</span>    <span class='comment'>#     Output only. Value of the specific cell in the confusion matrix.
</span>    <span class='comment'>#     The number of values each row has (i.e. the length of the row) is equal
</span>    <span class='comment'>#     to the length of the `annotation_spec_id` field or, if that one is not
</span>    <span class='comment'>#     populated, length of the {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix#display_name display_name} field.
</span>    <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="Row.html" title="Google::Cloud::AutoML::V1beta1::Row (class)">Row</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="confusion_matrix=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="confusion_matrix-instance_method">
  
    #<strong>confusion_matrix</strong>  &#x21d2; <tt><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfusionMatrix.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix (class)">Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix</a></span></tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns Output only. Confusion matrix of the evaluation.
Only set for MULTICLASS classification problems where number
of labels is no more than 10.
Only set for model level evaluation, not for evaluation per label.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfusionMatrix.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix (class)">Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix</a></span></tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>Output only. Confusion matrix of the evaluation.
Only set for MULTICLASS classification problems where number
of labels is no more than 10.
Only set for model level evaluation, not for evaluation per label.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/automl/v1beta1/doc/google/cloud/automl/v1beta1/classification.rb', line 102</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics (class)">ClassificationEvaluationMetrics</a></span></span>
  <span class='comment'># Metrics for a single confidence threshold.
</span>  <span class='comment'># @!attribute [rw] confidence_threshold
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     never returns predictions with score lower than this value.
</span>  <span class='comment'># @!attribute [rw] position_threshold
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     always returns at most this many predictions (ordered by their score,
</span>  <span class='comment'>#     descendingly), but they all still need to meet the confidence_threshold.
</span>  <span class='comment'># @!attribute [rw] recall
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Recall (True Positive Rate) for the given confidence
</span>  <span class='comment'>#     threshold.
</span>  <span class='comment'># @!attribute [rw] precision
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Precision for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. False Positive Rate for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] f1_score
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of recall and precision.
</span>  <span class='comment'># @!attribute [rw] recall_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The Recall (True Positive Rate) when only considering the
</span>  <span class='comment'>#     label that has the highest prediction score and not below the confidence
</span>  <span class='comment'>#     threshold for each example.
</span>  <span class='comment'># @!attribute [rw] precision_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The precision when only considering the label that has the
</span>  <span class='comment'>#     highest prediction score and not below the confidence threshold for each
</span>  <span class='comment'>#     example.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The False Positive Rate when only considering the label that
</span>  <span class='comment'>#     has the highest prediction score and not below the confidence threshold
</span>  <span class='comment'>#     for each example.
</span>  <span class='comment'># @!attribute [rw] f1_score_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#recall_at1 recall_at1} and {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#precision_at1 precision_at1}.
</span>  <span class='comment'># @!attribute [rw] true_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that match a ground truth
</span>  <span class='comment'>#     label.
</span>  <span class='comment'># @!attribute [rw] false_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that do not match a
</span>  <span class='comment'>#     ground truth label.
</span>  <span class='comment'># @!attribute [rw] false_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of ground truth labels that are not matched
</span>  <span class='comment'>#     by a model created label.
</span>  <span class='comment'># @!attribute [rw] true_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of labels that were not created by the model,
</span>  <span class='comment'>#     but if they would, they would not match a ground truth label.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfidenceMetricsEntry.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry (class)">ConfidenceMetricsEntry</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>

  <span class='comment'># Confusion matrix of the model running the classification.
</span>  <span class='comment'># @!attribute [rw] annotation_spec_id
</span>  <span class='comment'>#   @return [Array&lt;String&gt;]
</span>  <span class='comment'>#     Output only. IDs of the annotation specs used in the confusion matrix.
</span>  <span class='comment'>#     For Tables CLASSIFICATION
</span>  <span class='comment'>#
</span>  <span class='comment'>#     {Google::Cloud::AutoML::V1beta1::TablesModelMetadata#prediction_type prediction_type}
</span>  <span class='comment'>#     only list of {Annotation_spec_display_name-s} is populated.
</span>  <span class='comment'># @!attribute [rw] row
</span>  <span class='comment'>#   @return [Array&lt;Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix::Row&gt;]
</span>  <span class='comment'>#     Output only. Rows in the confusion matrix. The number of rows is equal to
</span>  <span class='comment'>#     the size of `annotation_spec_id`.
</span>  <span class='comment'>#     `row[i].value[j]` is the number of examples that have ground truth of the
</span>  <span class='comment'>#     `annotation_spec_id[i]` and are predicted as `annotation_spec_id[j]` by
</span>  <span class='comment'>#     the model being evaluated.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfusionMatrix.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix (class)">ConfusionMatrix</a></span></span>
    <span class='comment'># Output only. A row in the confusion matrix.
</span>    <span class='comment'># @!attribute [rw] example_count
</span>    <span class='comment'>#   @return [Array&lt;Integer&gt;]
</span>    <span class='comment'>#     Output only. Value of the specific cell in the confusion matrix.
</span>    <span class='comment'>#     The number of values each row has (i.e. the length of the row) is equal
</span>    <span class='comment'>#     to the length of the `annotation_spec_id` field or, if that one is not
</span>    <span class='comment'>#     populated, length of the {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix#display_name display_name} field.
</span>    <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="Row.html" title="Google::Cloud::AutoML::V1beta1::Row (class)">Row</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="log_loss=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="log_loss-instance_method">
  
    #<strong>log_loss</strong>  &#x21d2; <tt>Float</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns Output only. The Log Loss metric.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Float</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>Output only. The Log Loss metric.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/automl/v1beta1/doc/google/cloud/automl/v1beta1/classification.rb', line 102</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics (class)">ClassificationEvaluationMetrics</a></span></span>
  <span class='comment'># Metrics for a single confidence threshold.
</span>  <span class='comment'># @!attribute [rw] confidence_threshold
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     never returns predictions with score lower than this value.
</span>  <span class='comment'># @!attribute [rw] position_threshold
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. Metrics are computed with an assumption that the model
</span>  <span class='comment'>#     always returns at most this many predictions (ordered by their score,
</span>  <span class='comment'>#     descendingly), but they all still need to meet the confidence_threshold.
</span>  <span class='comment'># @!attribute [rw] recall
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Recall (True Positive Rate) for the given confidence
</span>  <span class='comment'>#     threshold.
</span>  <span class='comment'># @!attribute [rw] precision
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. Precision for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. False Positive Rate for the given confidence threshold.
</span>  <span class='comment'># @!attribute [rw] f1_score
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of recall and precision.
</span>  <span class='comment'># @!attribute [rw] recall_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The Recall (True Positive Rate) when only considering the
</span>  <span class='comment'>#     label that has the highest prediction score and not below the confidence
</span>  <span class='comment'>#     threshold for each example.
</span>  <span class='comment'># @!attribute [rw] precision_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The precision when only considering the label that has the
</span>  <span class='comment'>#     highest prediction score and not below the confidence threshold for each
</span>  <span class='comment'>#     example.
</span>  <span class='comment'># @!attribute [rw] false_positive_rate_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The False Positive Rate when only considering the label that
</span>  <span class='comment'>#     has the highest prediction score and not below the confidence threshold
</span>  <span class='comment'>#     for each example.
</span>  <span class='comment'># @!attribute [rw] f1_score_at1
</span>  <span class='comment'>#   @return [Float]
</span>  <span class='comment'>#     Output only. The harmonic mean of {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#recall_at1 recall_at1} and {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry#precision_at1 precision_at1}.
</span>  <span class='comment'># @!attribute [rw] true_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that match a ground truth
</span>  <span class='comment'>#     label.
</span>  <span class='comment'># @!attribute [rw] false_positive_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of model created labels that do not match a
</span>  <span class='comment'>#     ground truth label.
</span>  <span class='comment'># @!attribute [rw] false_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of ground truth labels that are not matched
</span>  <span class='comment'>#     by a model created label.
</span>  <span class='comment'># @!attribute [rw] true_negative_count
</span>  <span class='comment'>#   @return [Integer]
</span>  <span class='comment'>#     Output only. The number of labels that were not created by the model,
</span>  <span class='comment'>#     but if they would, they would not match a ground truth label.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfidenceMetricsEntry.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfidenceMetricsEntry (class)">ConfidenceMetricsEntry</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>

  <span class='comment'># Confusion matrix of the model running the classification.
</span>  <span class='comment'># @!attribute [rw] annotation_spec_id
</span>  <span class='comment'>#   @return [Array&lt;String&gt;]
</span>  <span class='comment'>#     Output only. IDs of the annotation specs used in the confusion matrix.
</span>  <span class='comment'>#     For Tables CLASSIFICATION
</span>  <span class='comment'>#
</span>  <span class='comment'>#     {Google::Cloud::AutoML::V1beta1::TablesModelMetadata#prediction_type prediction_type}
</span>  <span class='comment'>#     only list of {Annotation_spec_display_name-s} is populated.
</span>  <span class='comment'># @!attribute [rw] row
</span>  <span class='comment'>#   @return [Array&lt;Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix::Row&gt;]
</span>  <span class='comment'>#     Output only. Rows in the confusion matrix. The number of rows is equal to
</span>  <span class='comment'>#     the size of `annotation_spec_id`.
</span>  <span class='comment'>#     `row[i].value[j]` is the number of examples that have ground truth of the
</span>  <span class='comment'>#     `annotation_spec_id[i]` and are predicted as `annotation_spec_id[j]` by
</span>  <span class='comment'>#     the model being evaluated.
</span>  <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="ClassificationEvaluationMetrics/ConfusionMatrix.html" title="Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix (class)">ConfusionMatrix</a></span></span>
    <span class='comment'># Output only. A row in the confusion matrix.
</span>    <span class='comment'># @!attribute [rw] example_count
</span>    <span class='comment'>#   @return [Array&lt;Integer&gt;]
</span>    <span class='comment'>#     Output only. Value of the specific cell in the confusion matrix.
</span>    <span class='comment'>#     The number of values each row has (i.e. the length of the row) is equal
</span>    <span class='comment'>#     to the length of the `annotation_spec_id` field or, if that one is not
</span>    <span class='comment'>#     populated, length of the {Google::Cloud::AutoML::V1beta1::ClassificationEvaluationMetrics::ConfusionMatrix#display_name display_name} field.
</span>    <span class='kw'>class</span> <span class='const'><span class='object_link'><a href="Row.html" title="Google::Cloud::AutoML::V1beta1::Row (class)">Row</a></span></span><span class='semicolon'>;</span> <span class='kw'>end</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
  </div>


</div>

  <div id="footer">
  <ul class="footer-links">
    <li>
      <a href="https://github.com/GoogleCloudPlatform/google-cloud-ruby" title="Google Cloud on Github">
        <img src="/google-cloud-ruby/img/icon-link-github.svg" alt="GitHub icon"> GitHub
      </a>
    </li>
    <li>
      <a href="https://github.com/GoogleCloudPlatform/google-cloud-ruby/issues" title="Google Cloud issues on Github">
        <img src="/google-cloud-ruby/img/icon-link-github.svg" alt="GitHub icon"> Issues
      </a>
    </li>
    <li>
      <a href="http://stackoverflow.com/questions/tagged/google-cloud-ruby" title="Google Cloud on StackOverflow">
      <img src="/google-cloud-ruby/img/icon-link-stackoverflow.svg" alt="StackOverflow icon"> StackOverflow
    </a>
    </li>
    <li>
      <a href="http://rubygems.org/gems/google-cloud" title="Google Cloud on RubyGems">
        <img src="/google-cloud-ruby/img/icon-link-package-manager.svg" alt="RubyGems icon"> RubyGems
      </a>
    </li>
  </ul>

  <p>
    Documentation generated by <a href="http://yardoc.org" title="Yay! A Ruby Documentation Tool">yard</a>.
  </p>
</div>

</div>
