---
layout: yard_main
title: "Class: Google::Cloud::Speech::V1::RecognitionConfig - Cloud"
css: 
  - /docs/css/style.css
  - /docs/css/common.css
  - /css/yard-main.css
js: 
  - /docs/js/app.js
  - /js/yard-main.js
---
<script type="text/javascript" charset="utf-8">
  pathId = "Google::Cloud::Speech::V1::RecognitionConfig";
  relpath = '../../../../';
</script>


<div class="nav_wrap">
  <iframe id="nav" src="../../../../class_list.html?1"></iframe>
  <div id="resizer"></div>
</div>

<div id="main" tabindex="-1">
  <div id="header">
    <div id="menu">
  
    <a href="../../../../_index.html">Index (R)</a> &raquo;
    <span class='title'><span class='object_link'><a href="../../../../Google.html" title="Google (module)">Google</a></span></span> &raquo; <span class='title'><span class='object_link'><a href="../../../Cloud.html" title="Google::Cloud (module)">Cloud</a></span></span> &raquo; <span class='title'><span class='object_link'><a href="../../Speech.html" title="Google::Cloud::Speech (module)">Speech</a></span></span> &raquo; <span class='title'><span class='object_link'><a href="../V1.html" title="Google::Cloud::Speech::V1 (module)">V1</a></span></span>
     &raquo; 
    <span class="title">RecognitionConfig</span>
  
</div>

    <div id="search">
  
    <a class="full_list_link" id="class_list_link"
        href="../../../../class_list.html">

        <svg width="24" height="24">
          <rect x="0" y="4" width="24" height="4" rx="1" ry="1"></rect>
          <rect x="0" y="12" width="24" height="4" rx="1" ry="1"></rect>
          <rect x="0" y="20" width="24" height="4" rx="1" ry="1"></rect>
        </svg>
    </a>
  
</div>
    <div class="clear"></div>
  </div>

  <div id="content"><h1>Class: Google::Cloud::Speech::V1::RecognitionConfig
  
  
  
</h1>
<div class="box_info">
  
  <dl>
    <dt>Inherits:</dt>
    <dd>
      <span class="inheritName">Object</span>
      
        <ul class="fullTree">
          <li>Object</li>
          
            <li class="next">Google::Cloud::Speech::V1::RecognitionConfig</li>
          
        </ul>
        <a href="#" class="inheritanceTree">show all</a>
      
    </dd>
  </dl>
  

  
  
  
  
  

  

  
  <dl>
    <dt>Defined in:</dt>
    <dd>lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb</dd>
  </dl>
  
</div>

<h2>Overview</h2><div class="docstring">
  <div class="discussion">
    <p>Provides information to the recognizer that specifies how to process the
request.</p>


  </div>
</div>
<div class="tags">
  

</div><h2>Defined Under Namespace</h2>
<p class="children">
  
    
      <strong class="modules">Modules:</strong> <span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span>
    
  
    
  
</p>




  <h2>Instance Attribute Summary <small><a href="#" class="summary_toggle">collapse</a></small></h2>
  <ul class="summary">
    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#audio_channel_count-instance_method" title="#audio_channel_count (instance method)">#<strong>audio_channel_count</strong>  &#x21d2; Integer </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> The number of channels in the input audio data.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#enable_automatic_punctuation-instance_method" title="#enable_automatic_punctuation (instance method)">#<strong>enable_automatic_punctuation</strong>  &#x21d2; true, false </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> If &#39;true&#39;, adds punctuation to recognition result hypotheses.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#enable_separate_recognition_per_channel-instance_method" title="#enable_separate_recognition_per_channel (instance method)">#<strong>enable_separate_recognition_per_channel</strong>  &#x21d2; true, false </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>This needs to be set to <code>true</code> explicitly and <code>audio_channel_count</code> &gt; 1 to get each channel recognized separately.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#enable_word_time_offsets-instance_method" title="#enable_word_time_offsets (instance method)">#<strong>enable_word_time_offsets</strong>  &#x21d2; true, false </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> If <code>true</code>, the top result includes a list of words and the start and end time offsets (timestamps) for those words.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#encoding-instance_method" title="#encoding (instance method)">#<strong>encoding</strong>  &#x21d2; Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>Encoding of audio data sent in all <code>RecognitionAudio</code> messages.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#language_code-instance_method" title="#language_code (instance method)">#<strong>language_code</strong>  &#x21d2; String </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Required</em> The language of the supplied audio as a <a href="https://www.rfc-editor.org/rfc/bcp/bcp47.txt">BCP-47</a> language tag.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#max_alternatives-instance_method" title="#max_alternatives (instance method)">#<strong>max_alternatives</strong>  &#x21d2; Integer </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> Maximum number of recognition hypotheses to be returned.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#metadata-instance_method" title="#metadata (instance method)">#<strong>metadata</strong>  &#x21d2; Google::Cloud::Speech::V1::RecognitionMetadata </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> Metadata regarding this request.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#model-instance_method" title="#model (instance method)">#<strong>model</strong>  &#x21d2; String </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> Which model to select for the given request.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#profanity_filter-instance_method" title="#profanity_filter (instance method)">#<strong>profanity_filter</strong>  &#x21d2; true, false </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> If set to <code>true</code>, the server will attempt to filter out profanities, replacing all but the initial character in each filtered word with asterisks, e.g.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#sample_rate_hertz-instance_method" title="#sample_rate_hertz (instance method)">#<strong>sample_rate_hertz</strong>  &#x21d2; Integer </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>Sample rate in Hertz of the audio data sent in all <code>RecognitionAudio</code> messages.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#speech_contexts-instance_method" title="#speech_contexts (instance method)">#<strong>speech_contexts</strong>  &#x21d2; Array&lt;Google::Cloud::Speech::V1::SpeechContext&gt; </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> array of <span class='object_link'><a href="SpeechContext.html" title="Google::Cloud::Speech::V1::SpeechContext (class)">SpeechContext</a></span>.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#use_enhanced-instance_method" title="#use_enhanced (instance method)">#<strong>use_enhanced</strong>  &#x21d2; true, false </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> Set to true to use an enhanced model for speech recognition.</p>
</div></span>
  
</li>

    
  </ul>





  <div id="instance_attr_details" class="attr_details">
    <h2>Instance Attribute Details</h2>
    
      
      <span id="audio_channel_count=-instance_method"></span>
      <div class="method_details first">
  <h3 class="signature first" id="audio_channel_count-instance_method">
  
    #<strong>audio_channel_count</strong>  &#x21d2; <tt>Integer</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> The number of channels in the input audio data.
ONLY set this for MULTI-CHANNEL recognition.
Valid values for LINEAR16 and FLAC are <code>1</code>-<code>8</code>.
Valid values for OGG_OPUS are &#39;1&#39;-&#39;254&#39;.
Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only <code>1</code>.
If <code>0</code> or omitted, defaults to one channel (mono).
Note: We only recognize the first channel by default.
To perform independent recognition on each channel set
<code>enable_separate_recognition_per_channel</code> to &#39;true&#39;.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Integer</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> The number of channels in the input audio data.
ONLY set this for MULTI-CHANNEL recognition.
Valid values for LINEAR16 and FLAC are <code>1</code>-<code>8</code>.
Valid values for OGG_OPUS are &#39;1&#39;-&#39;254&#39;.
Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only <code>1</code>.
If <code>0</code> or omitted, defaults to one channel (mono).
Note: We only recognize the first channel by default.
To perform independent recognition on each channel set
<code>enable_separate_recognition_per_channel</code> to &#39;true&#39;.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="enable_automatic_punctuation=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="enable_automatic_punctuation-instance_method">
  
    #<strong>enable_automatic_punctuation</strong>  &#x21d2; <tt>true</tt>, <tt>false</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> If &#39;true&#39;, adds punctuation to recognition result hypotheses.
This feature is only available in select languages. Setting this for
requests in other languages has no effect at all.
The default &#39;false&#39; value does not add punctuation to result hypotheses.
Note: This is currently offered as an experimental service, complimentary
to all users. In the future this may be exclusively available as a
premium feature.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>true</tt>, <tt>false</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> If &#39;true&#39;, adds punctuation to recognition result hypotheses.
This feature is only available in select languages. Setting this for
requests in other languages has no effect at all.
The default &#39;false&#39; value does not add punctuation to result hypotheses.
Note: This is currently offered as an experimental service, complimentary
to all users. In the future this may be exclusively available as a
premium feature.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="enable_separate_recognition_per_channel=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="enable_separate_recognition_per_channel-instance_method">
  
    #<strong>enable_separate_recognition_per_channel</strong>  &#x21d2; <tt>true</tt>, <tt>false</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns This needs to be set to <code>true</code> explicitly and <code>audio_channel_count</code> &gt; 1
to get each channel recognized separately. The recognition result will
contain a <code>channel_tag</code> field to state which channel that result belongs
to. If this is not true, we will only recognize the first channel. The
request is billed cumulatively for all channels recognized:
<code>audio_channel_count</code> multiplied by the length of the audio.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>true</tt>, <tt>false</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>This needs to be set to <code>true</code> explicitly and <code>audio_channel_count</code> &gt; 1
to get each channel recognized separately. The recognition result will
contain a <code>channel_tag</code> field to state which channel that result belongs
to. If this is not true, we will only recognize the first channel. The
request is billed cumulatively for all channels recognized:
<code>audio_channel_count</code> multiplied by the length of the audio.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="enable_word_time_offsets=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="enable_word_time_offsets-instance_method">
  
    #<strong>enable_word_time_offsets</strong>  &#x21d2; <tt>true</tt>, <tt>false</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> If <code>true</code>, the top result includes a list of words and
the start and end time offsets (timestamps) for those words. If
<code>false</code>, no word-level time offset information is returned. The default is
<code>false</code>.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>true</tt>, <tt>false</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> If <code>true</code>, the top result includes a list of words and
the start and end time offsets (timestamps) for those words. If
<code>false</code>, no word-level time offset information is returned. The default is
<code>false</code>.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="encoding=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="encoding-instance_method">
  
    #<strong>encoding</strong>  &#x21d2; <tt><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding</a></span></tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns Encoding of audio data sent in all <code>RecognitionAudio</code> messages.
This field is optional for <code>FLAC</code> and <code>WAV</code> audio files and required
for all other audio formats. For details, see
<span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span>.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding</a></span></tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>Encoding of audio data sent in all <code>RecognitionAudio</code> messages.
This field is optional for <code>FLAC</code> and <code>WAV</code> audio files and required
for all other audio formats. For details, see
<span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span>.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="language_code=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="language_code-instance_method">
  
    #<strong>language_code</strong>  &#x21d2; <tt>String</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Required</em> The language of the supplied audio as a
<a href="https://www.rfc-editor.org/rfc/bcp/bcp47.txt">BCP-47</a> language tag.
Example: &quot;en-US&quot;.
See <a href="https://cloud.google.com/speech-to-text/docs/languages">Language Support</a>
for a list of the currently supported language codes.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>String</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Required</em> The language of the supplied audio as a
<a href="https://www.rfc-editor.org/rfc/bcp/bcp47.txt">BCP-47</a> language tag.
Example: &quot;en-US&quot;.
See <a href="https://cloud.google.com/speech-to-text/docs/languages">Language Support</a>
for a list of the currently supported language codes.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="max_alternatives=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="max_alternatives-instance_method">
  
    #<strong>max_alternatives</strong>  &#x21d2; <tt>Integer</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> Maximum number of recognition hypotheses to be returned.
Specifically, the maximum number of <code>SpeechRecognitionAlternative</code> messages
within each <code>SpeechRecognitionResult</code>.
The server may return fewer than <code>max_alternatives</code>.
Valid values are <code>0</code>-<code>30</code>. A value of <code>0</code> or <code>1</code> will return a maximum of
one. If omitted, will return a maximum of one.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Integer</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> Maximum number of recognition hypotheses to be returned.
Specifically, the maximum number of <code>SpeechRecognitionAlternative</code> messages
within each <code>SpeechRecognitionResult</code>.
The server may return fewer than <code>max_alternatives</code>.
Valid values are <code>0</code>-<code>30</code>. A value of <code>0</code> or <code>1</code> will return a maximum of
one. If omitted, will return a maximum of one.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="metadata=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="metadata-instance_method">
  
    #<strong>metadata</strong>  &#x21d2; <tt><span class='object_link'><a href="RecognitionMetadata.html" title="Google::Cloud::Speech::V1::RecognitionMetadata (class)">Google::Cloud::Speech::V1::RecognitionMetadata</a></span></tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> Metadata regarding this request.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt><span class='object_link'><a href="RecognitionMetadata.html" title="Google::Cloud::Speech::V1::RecognitionMetadata (class)">Google::Cloud::Speech::V1::RecognitionMetadata</a></span></tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> Metadata regarding this request.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="model=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="model-instance_method">
  
    #<strong>model</strong>  &#x21d2; <tt>String</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> Which model to select for the given request. Select the model
best suited to your domain to get best results. If a model is not
explicitly specified, then we auto-select a model based on the parameters
in the RecognitionConfig.</p>

<table>
  <tr>
    <td><b>Model</b></td>
    <td><b>Description</b></td>
  </tr>
  <tr>
    <td><code>command_and_search</code></td>
    <td>Best for short queries such as voice commands or voice search.</td>
  </tr>
  <tr>
    <td><code>phone_call</code></td>
    <td>Best for audio that originated from a phone call (typically
    recorded at an 8khz sampling rate).</td>
  </tr>
  <tr>
    <td><code>video</code></td>
    <td>Best for audio that originated from from video or includes multiple
        speakers. Ideally the audio is recorded at a 16khz or greater
        sampling rate. This is a premium model that costs more than the
        standard rate.</td>
  </tr>
  <tr>
    <td><code>default</code></td>
    <td>Best for audio that is not one of the specific audio models.
        For example, long-form audio. Ideally the audio is high-fidelity,
        recorded at a 16khz or greater sampling rate.</td>
  </tr>
</table>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>String</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> Which model to select for the given request. Select the model
best suited to your domain to get best results. If a model is not
explicitly specified, then we auto-select a model based on the parameters
in the RecognitionConfig.</p>

<table>
  <tr>
    <td><b>Model</b></td>
    <td><b>Description</b></td>
  </tr>
  <tr>
    <td><code>command_and_search</code></td>
    <td>Best for short queries such as voice commands or voice search.</td>
  </tr>
  <tr>
    <td><code>phone_call</code></td>
    <td>Best for audio that originated from a phone call (typically
    recorded at an 8khz sampling rate).</td>
  </tr>
  <tr>
    <td><code>video</code></td>
    <td>Best for audio that originated from from video or includes multiple
        speakers. Ideally the audio is recorded at a 16khz or greater
        sampling rate. This is a premium model that costs more than the
        standard rate.</td>
  </tr>
  <tr>
    <td><code>default</code></td>
    <td>Best for audio that is not one of the specific audio models.
        For example, long-form audio. Ideally the audio is high-fidelity,
        recorded at a 16khz or greater sampling rate.</td>
  </tr>
</table>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="profanity_filter=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="profanity_filter-instance_method">
  
    #<strong>profanity_filter</strong>  &#x21d2; <tt>true</tt>, <tt>false</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> If set to <code>true</code>, the server will attempt to filter out
profanities, replacing all but the initial character in each filtered word
with asterisks, e.g. &quot;f***&quot;. If set to <code>false</code> or omitted, profanities
won&#39;t be filtered out.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>true</tt>, <tt>false</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> If set to <code>true</code>, the server will attempt to filter out
profanities, replacing all but the initial character in each filtered word
with asterisks, e.g. &quot;f***&quot;. If set to <code>false</code> or omitted, profanities
won&#39;t be filtered out.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="sample_rate_hertz=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="sample_rate_hertz-instance_method">
  
    #<strong>sample_rate_hertz</strong>  &#x21d2; <tt>Integer</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns Sample rate in Hertz of the audio data sent in all
<code>RecognitionAudio</code> messages. Valid values are: 8000-48000.
16000 is optimal. For best results, set the sampling rate of the audio
source to 16000 Hz. If that&#39;s not possible, use the native sample rate of
the audio source (instead of re-sampling).
This field is optional for <code>FLAC</code> and <code>WAV</code> audio files and required
for all other audio formats. For details, see
<span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span>.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Integer</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>Sample rate in Hertz of the audio data sent in all
<code>RecognitionAudio</code> messages. Valid values are: 8000-48000.
16000 is optimal. For best results, set the sampling rate of the audio
source to 16000 Hz. If that&#39;s not possible, use the native sample rate of
the audio source (instead of re-sampling).
This field is optional for <code>FLAC</code> and <code>WAV</code> audio files and required
for all other audio formats. For details, see
<span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span>.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="speech_contexts=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="speech_contexts-instance_method">
  
    #<strong>speech_contexts</strong>  &#x21d2; <tt>Array&lt;<span class='object_link'><a href="SpeechContext.html" title="Google::Cloud::Speech::V1::SpeechContext (class)">Google::Cloud::Speech::V1::SpeechContext</a></span>&gt;</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> array of <span class='object_link'><a href="SpeechContext.html" title="Google::Cloud::Speech::V1::SpeechContext (class)">SpeechContext</a></span>.
A means to provide context to assist the speech recognition. For more
information, see <a href="https://cloud.google.com/speech-to-text/docs/basics#phrase-hints">Phrase Hints</a>.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Array&lt;<span class='object_link'><a href="SpeechContext.html" title="Google::Cloud::Speech::V1::SpeechContext (class)">Google::Cloud::Speech::V1::SpeechContext</a></span>&gt;</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> array of <span class='object_link'><a href="SpeechContext.html" title="Google::Cloud::Speech::V1::SpeechContext (class)">SpeechContext</a></span>.
A means to provide context to assist the speech recognition. For more
information, see <a href="https://cloud.google.com/speech-to-text/docs/basics#phrase-hints">Phrase Hints</a>.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="use_enhanced=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="use_enhanced-instance_method">
  
    #<strong>use_enhanced</strong>  &#x21d2; <tt>true</tt>, <tt>false</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> Set to true to use an enhanced model for speech recognition.
If <code>use_enhanced</code> is set to true and the <code>model</code> field is not set, then
an appropriate enhanced model is chosen if an enhanced model exists for
the audio.</p>

<p>If <code>use_enhanced</code> is true and an enhanced version of the specified model
does not exist, then the speech is recognized using the standard version
of the specified model.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>true</tt>, <tt>false</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> Set to true to use an enhanced model for speech recognition.
If <code>use_enhanced</code> is set to true and the <code>model</code> field is not set, then
an appropriate enhanced model is chosen if an enhanced model exists for
the audio.</p>

<p>If <code>use_enhanced</code> is true and an enhanced version of the specified model
does not exist, then the speech is recognized using the standard version
of the specified model.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1/doc/google/cloud/speech/v1/cloud_speech.rb', line 215</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, and `SPEEX_WITH_HEADER_BYTE`.
</span>  <span class='comment'>#
</span>  <span class='comment'># The `FLAC` and `WAV` audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for `WAV` files that
</span>  <span class='comment'># contain either `LINEAR16` or `MULAW` encoded audio.
</span>  <span class='comment'># If you send `FLAC` or `WAV` audio file format in
</span>  <span class='comment'># your request, you do not need to specify an `AudioEncoding`; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error
</span>  <span class='comment'># code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># `FLAC` (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># `STREAMINFO` are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, `OGG_OPUS` is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># `audio/x-speex-with-header-byte`.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. `sample_rate_hertz` must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
  </div>


</div>

  <div id="footer">
  <ul class="footer-links">
    <li>
      <a href="https://github.com/GoogleCloudPlatform/google-cloud-ruby" title="Google Cloud on Github">
        <img src="/google-cloud-ruby/img/icon-link-github.svg" alt="GitHub icon"> GitHub
      </a>
    </li>
    <li>
      <a href="https://github.com/GoogleCloudPlatform/google-cloud-ruby/issues" title="Google Cloud issues on Github">
        <img src="/google-cloud-ruby/img/icon-link-github.svg" alt="GitHub icon"> Issues
      </a>
    </li>
    <li>
      <a href="http://stackoverflow.com/questions/tagged/google-cloud-ruby" title="Google Cloud on StackOverflow">
      <img src="/google-cloud-ruby/img/icon-link-stackoverflow.svg" alt="StackOverflow icon"> StackOverflow
    </a>
    </li>
    <li>
      <a href="http://rubygems.org/gems/google-cloud" title="Google Cloud on RubyGems">
        <img src="/google-cloud-ruby/img/icon-link-package-manager.svg" alt="RubyGems icon"> RubyGems
      </a>
    </li>
  </ul>

  <p>
    Documentation generated by <a href="http://yardoc.org" title="Yay! A Ruby Documentation Tool">yard</a>.
  </p>
</div>

</div>
